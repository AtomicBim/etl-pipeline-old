{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3abbfb4",
   "metadata": {},
   "source": [
    "## –ò–º–ø–æ—Ä—Ç—ã, –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏ —Å–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce6f1d",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nfrom sqlalchemy import create_engine\nimport pathlib\nimport os\n\nBASE_DIR = pathlib.Path(os.environ['ETL_ROOT'])\nRAW_DIR = BASE_DIR / 'raw_data'\nPROC_DIR = BASE_DIR / 'processed'\n\nad_path                        = RAW_DIR / 'tim_export_ad_user.csv'\nsync_path                      = RAW_DIR / 'tim_export_project_sync.csv'\n\nsave_path = PROC_DIR / 'sync_transformed.csv'\n\nengine_postgres = create_engine(\"postgresql+psycopg2://postgres:Q!w2e3r4@192.168.42.188:5430/postgres\")\nengine_pluginsdb = create_engine(\"postgresql+psycopg2://postgres:Q!w2e3r4@192.168.42.188:5430/pluginsdb\")"
  },
  {
   "cell_type": "markdown",
   "id": "48ca2d7a",
   "metadata": {},
   "source": [
    "## –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–æ–≤ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efe1416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ad = pd.read_csv(ad_path)\n",
    "df_sync = pd.read_csv(sync_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37703e5",
   "metadata": {},
   "source": [
    "## –°–ª–∏—è–Ω–∏–µ —Å AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3f8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sync = df_sync.merge(\n",
    "    df_ad[[\"display_name\", \"department\", \"project_section\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"user_display_name\",\n",
    "    right_on=\"display_name\"\n",
    ").drop(columns=\"display_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225895f",
   "metadata": {},
   "source": [
    "## –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57f67118",
   "metadata": {},
   "outputs": [],
   "source": [
    "bim_users = {\n",
    "    '–ö–æ–ª–ø–∞–∫–æ–≤ –°–µ–º–µ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á','–ü—è—Ç–∫–æ–≤ –†–æ–º–∞–Ω –ê–Ω–∞—Ç–æ–ª—å–µ–≤–∏—á',\n",
    "    '–ê–Ω–¥—Ä–µ–µ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω–æ–≤–∏—á','–ö–∏—á–∏–≥–∏–Ω –ê–Ω–¥—Ä–µ–π –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á',\n",
    "    '–ü–∞–Ω–æ–≤ –ê–Ω—Ç–æ–Ω –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á','–í–∞—Å—å–∫–æ–≤ –î–µ–Ω–∏—Å –ò–≥–æ—Ä–µ–≤–∏—á','–ü–æ–ø–æ–≤ –ê–Ω—Ç–æ–Ω –ú–∏—Ö–∞–π–ª–æ–≤–∏—á',\n",
    "    '–ö—É–∑–æ–≤–ª–µ–≤–∞ –û–ª—å–≥–∞ –°–µ—Ä–≥–µ–µ–≤–Ω–∞','–ö–∞–ª–∞—á–µ–≤ –î–∞–Ω–∏–∏–ª –ê—Ä—Ç–µ–º–æ–≤–∏—á',\n",
    "    '–ì—Ä–∏–≥–æ—Ä—å–µ–≤ –†–æ–º–∞–Ω –ù–∏–∫–æ–ª–∞–µ–≤–∏—á','–ö—Ä–∞—Å–∏–ª—å–Ω–∏–∫–æ–≤ –î–º–∏—Ç—Ä–∏–π –°–µ—Ä–≥–µ–µ–≤–∏—á',\n",
    "    '–õ–∏—Ç—É–µ–≤–∞ –Æ–ª–∏—è –î–º–∏—Ç—Ä–∏–µ–≤–Ω–∞','–ñ—É–∫ –í–∏—Ç–∞–ª–∏–π –¢–æ–º–∞—à–µ–≤–∏—á','–û–≤—Å—è–Ω–∫–∏–Ω –†–æ–º–∞–Ω –ù–∏–∫–æ–ª–∞–µ–≤–∏—á',\n",
    "    '–†–æ–º–∞–Ω–æ–≤–∞ –ê–Ω–Ω–∞ –í—è—á–µ—Å–ª–∞–≤–æ–≤–Ω–∞','–ö–æ–Ω–æ–≤–∞–ª–æ–≤ –í–∞—Å–∏–ª–∏–π –°–µ—Ä–≥–µ–µ–≤–∏—á',\n",
    "    '–£—Ä–º–∞–Ω—á–µ–µ–≤ –†–æ–º–∞–Ω –î–∞–º–∏—Ä–æ–≤–∏—á', '–î–æ–∫–ª–∞–¥—á–∏–∫ 708'\n",
    "}\n",
    "\n",
    "df_sync[\"is_bim\"] = df_sync[\"user_display_name\"].isin(bim_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8cce841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_short_name(name: str) -> str:\n",
    "    parts = name.split('_')\n",
    "    return '_'.join(parts[:2]) if len(parts) >= 2 else name\n",
    "\n",
    "df_sync['short_project_name'] = df_sync['project_name'].astype(str).apply(extract_short_name)\n",
    "\n",
    "df_sync = df_sync.drop(columns=[\n",
    "    'program_name',\n",
    "    'program_version',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26b6aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_atom = df_sync[\"project_name\"].str.contains(\n",
    "    \"–ê–¢–û–ú|–î–û–£|08-12|–ò–ö–ü|ATOM|–ê–ü–£\", case=False, na=False\n",
    ")\n",
    "\n",
    "df_sync[\"object_name\"] = np.select(\n",
    "    [\n",
    "        df_sync[\"project_name\"].str.contains(\"–°–ü.–õ–õ–£|—Å—Ç–∞–Ω–¥–∞—Ä—Ç|—É–∑–ª—ã|—É–∑–µ–ª|–±–∏–±–ª–∏–æ—Ç–µ–∫–∞\", case=False, na=False),\n",
    "        mask_atom,\n",
    "        df_sync[\"project_name\"].str.contains(\"K01\", case=False, na=False),\n",
    "        df_sync[\"project_name\"].str.contains(\"–ò–ù–ü–†–û\", case=False, na=False),\n",
    "        df_sync[\"project_name\"].str.contains(\"–Ø–ª—Ç–∞\", case=False, na=False)\n",
    "    ],\n",
    "    [\n",
    "        \"–£–∑–ª—ã –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã\",\n",
    "        \"–ê–¢–û–ú\",\n",
    "        \"–ö–æ—Ä—Ç—Ä–æ—Å\",\n",
    "        \"–ò–ù–ü–†–û\",\n",
    "        \"–Ø–ª—Ç–∞\"\n",
    "    ],\n",
    "    default=\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc9ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sync[\"is_detached\"] = df_sync[\"project_name\"].str.contains(\"–æ—Ç—Å–æ–µ–¥–∏–Ω–µ–Ω–æ\", case=False, na=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ce27465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_storage_name(row):\n",
    "    project = row.get(\"project_name\")\n",
    "    username = row.get(\"username\")\n",
    "\n",
    "    if pd.isna(project) or pd.isna(username):\n",
    "        return project  # –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å\n",
    "\n",
    "    parts = str(project).split(\"_\")\n",
    "    if len(parts) < 2:\n",
    "        return project  # –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å\n",
    "\n",
    "    last_part = parts[-1].strip().lower()\n",
    "    user_name = str(username).strip().lower()\n",
    "\n",
    "    if last_part == user_name:\n",
    "        return \"_\".join(parts[:-1])\n",
    "    else:\n",
    "        return project  # –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å\n",
    "\n",
    "df_sync[\"file_storage_name\"] = df_sync.apply(extract_file_storage_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c11cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_solution(row):\n",
    "    name = str(row[\"project_name\"])\n",
    "    obj  = row[\"object_name\"]\n",
    "\n",
    "    if obj == \"–ö–æ—Ä—Ç—Ä–æ—Å\":\n",
    "        section_map_kortros = {\n",
    "            \"_AR\": \"–ê–†\", \"_AI\": \"–ê–ò\",\n",
    "            \"_KR\": \"–ö–†\", \"_AGK\": \"–ê–ì–ö\",\n",
    "            \"_VK\": \"–í–ö\", \"_EL\": \"–≠–õ\",\n",
    "            \"_OV\": \"–û–í\", \"_AK\": \"–ê–ö\",\n",
    "            \"_SS\": \"–°–°\", \"_P\": \"–ü\",\n",
    "            \"_R\": \"–†\", \"_TS\": \"–¢–°\",\n",
    "            \"_AP\": \"–ê–ü\"\n",
    "        }\n",
    "\n",
    "        for pattern, section in section_map_kortros.items():\n",
    "            if pattern in name:\n",
    "                return section\n",
    "        return \"–ù–î\"\n",
    "\n",
    "    else:\n",
    "        section_map_rus = {\n",
    "            \"_–ê–†\": \"–ê–†\", \"_–§–æ—Ä—ç—Å–∫–∏–∑\": \"–ê–†\",\n",
    "            \"_–ê–ò\": \"–ê–ò\", \"_–ö–ñ\": \"–ö–ñ\",\n",
    "            \"_–í–ö\": \"–í–ö\", \"_–≠–õ\": \"–≠–õ\",\n",
    "            \"_–¢–°\": \"–¢–°\", \"_–¢–•\": \"–¢–•\",\n",
    "            \"_–û–í\": \"–û–í\", \"_–ö–†\": \"–ö–†\",\n",
    "            \"_–ö–ú\": \"–ö–ú\", \"_–ê–ü\": \"–ê–ü\",\n",
    "            \"_–ü–¢\": \"–ü–¢\", \"_–°–°\": \"–°–°\",\n",
    "            \"_–ü–ë\": \"–ü–ë\", \"_–≠–ì\": \"–≠–ì\",\n",
    "             \"_–ê–ü\": \"–ê–ü\"\n",
    "        }\n",
    "\n",
    "        for pattern, section in section_map_rus.items():\n",
    "            if pattern in name:\n",
    "                return section\n",
    "        return \"–ù–î\"\n",
    "\n",
    "df_sync[\"project_solution_name\"] = df_sync.apply(get_project_solution, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b945d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_stage(row):\n",
    "    name = str(row[\"project_name\"])\n",
    "    obj = row[\"object_name\"]\n",
    "\n",
    "    if obj == \"–ö–æ—Ä—Ç—Ä–æ—Å\":\n",
    "        # –∫–æ—Ä—Ç–µ–∂: (—Ç–∏–ø_–ø—Ä–æ–≤–µ—Ä–∫–∏, –ø–∞—Ç—Ç–µ—Ä–Ω): –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        stage_map_kortros = {\n",
    "            (\"contains\", \"_P_\"): \"–ü\",\n",
    "            (\"contains\", \"_R_\"): \"–†\",\n",
    "            (\"contains\", \"_AGK_\"): \"–ì–ö\",\n",
    "            (\"endswith\", \"_P\"): \"–ü\",\n",
    "            (\"endswith\", \"_R\"): \"–†\",\n",
    "            (\"endswith\", \"_AGK\"): \"–ì–ö\"\n",
    "        }\n",
    "\n",
    "        for (mode, pattern), stage in stage_map_kortros.items():\n",
    "            if (mode == \"contains\" and pattern in name) or \\\n",
    "               (mode == \"endswith\" and name.endswith(pattern)):\n",
    "                return stage\n",
    "\n",
    "        return \"–ù–î\"\n",
    "\n",
    "    else:\n",
    "        stage_map = {\n",
    "            (\"contains\", \"_–ü_\"): \"–ü\",\n",
    "            (\"contains\", \"_–†_\"): \"–†\",\n",
    "            (\"contains\", \"_–†–î_\"): \"–†\",\n",
    "            (\"contains\", \"_–≠–ü_\"): \"–≠–ü\",\n",
    "            (\"contains\", \"_–§–æ—Ä—ç—Å–∫–∏–∑_\"): \"–≠–ü\",\n",
    "            (\"contains\", \"_–≠—Å–∫–∏–∑_\"): \"–≠–ü\",\n",
    "            (\"contains\", \"_–§–≠_\"): \"–≠–ü\",\n",
    "            (\"endswith\", \"_–ü\"): \"–ü\",\n",
    "            (\"endswith\", \"_–†\"): \"–†\",\n",
    "            (\"endswith\", \"_–†–î\"): \"–†\",\n",
    "            (\"endswith\", \"_–≠–ü\"): \"–≠–ü\",\n",
    "            (\"endswith\", \"_–§–æ—Ä—ç—Å–∫–∏–∑\"): \"–≠–ü\",\n",
    "            (\"endswith\", \"_–≠—Å–∫–∏–∑\"): \"–≠–ü\",\n",
    "            (\"endswith\", \"_–§–≠\"): \"–≠–ü\"\n",
    "        }\n",
    "\n",
    "        for (mode, pattern), stage in stage_map.items():\n",
    "            if (mode == \"contains\" and pattern in name) or \\\n",
    "               (mode == \"endswith\" and name.endswith(pattern)):\n",
    "                return stage\n",
    "\n",
    "        return \"–ù–î\"\n",
    "    \n",
    "df_sync[\"project_stage_name\"] = df_sync.apply(get_project_stage, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04a683aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = df_sync.select_dtypes(include='object').columns\n",
    "df_sync[str_cols] = df_sync[str_cols].fillna(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö\")\n",
    "\n",
    "num_cols = df_sync.select_dtypes(include=['number', 'Int64']).columns\n",
    "df_sync[num_cols] = df_sync[num_cols].fillna(0)\n",
    "\n",
    "date_cols = df_sync.select_dtypes(include='datetime').columns\n",
    "df_sync[date_cols] = df_sync[date_cols].fillna(pd.NaT)  # –ò–ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0a61cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sync_bim = df_sync[(df_sync['is_bim'] == True) & (df_sync['is_detached'] == 0)].copy()\n",
    "df_sync_designers = df_sync[(df_sync['is_bim'] == False) & (df_sync['is_detached'] == 0)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec76a9",
   "metadata": {},
   "source": [
    "## –ü–∏—à–µ–º –≤ –ë–î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca4c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé –ü–æ–¥–∫–ª—é—á–µ–Ω –∫ –±–∞–∑–µ: postgres\n",
      "üõ† –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã datalake.test_lake –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –∏–∑ DataFrame.\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: 240966\n",
      "üõ† –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã datalake.test_lake –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –∏–∑ DataFrame.\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: 16425\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ DataFrame‚Äë–æ–≤ –≤ PostgreSQL.\n",
    "\n",
    "**–ü–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω –∫–ª—é—á‚Äë–¥–∞—Ç–∞, –∞ –Ω–µ GUID?**\n",
    "-----------------------------------------------------------------\n",
    "* –í –≤–∞—à–∏—Ö –≤—ã–≥—Ä—É–∑–∫–∞—Ö —Å—Ç—Ä–æ–∫–∏ –ø–æ—è–≤–ª—è—é—Ç—Å—è *–æ–¥–∏–Ω —Ä–∞–∑* –∏ –±–æ–ª—å—à–µ –Ω–µ –º–µ–Ω—è—é—Ç—Å—è, –∞¬†–Ω–æ–≤—ã–µ ‚Äî –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –ø–æ–ª–µ–º‚Äë–¥–∞—Ç—ã (snapshot / update_date / loaded_at).\n",
    "* –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∑–∞ O(1) –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∏–Ω–¥–µ–∫—Å–∞ –∏ —Å—Ä–∞–∑—É –≥–æ–≤–æ—Ä–∏—Ç, –∫–∞–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –Ω–æ–≤—ã–µ.\n",
    "* GUID, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –ª–µ—Ç—É (`uuid4()`), –Ω–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω: –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—É—Å–∫–µ —Å—Ç–∞—Ä—ã–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ–ª—É—á–∞—Ç –¥—Ä—É–≥–∏–µ GUID‚Äë—ã –∏ –±—É–¥—É—Ç –≤—Å—Ç–∞–≤–ª–µ–Ω—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ.\n",
    "* –î–µ—Ç‚ÄëGUID –∏–∑ —Ö—ç—à–∞ —Å—Ç—Ä–æ–∫–∏ —Ç—Ä–µ–±—É–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –≤—Å—ë‚Äë—Ä–∞–≤–Ω–æ –¥—É–±–ª–∏—Ä—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –¥–∞—Ç—ã.\n",
    "\n",
    "–ò—Ç–æ–≥–æ: **–∫–ª—é—á‚Äë–¥–∞—Ç–∞ –ø—Ä–æ—â–µ, –±—ã—Å—Ç—Ä–µ–µ –∏ –Ω–µ –º–µ–Ω—è–µ—Ç —Å—Ö–µ–º—É –¥–∞–Ω–Ω—ã—Ö**.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "–°–∫—Ä–∏–ø—Ç\n",
    "====================================================================\n",
    "–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pandas, numpy, SQLAlchemy¬†‚â•1.4, psycopg2‚Äëbinary.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "SCHEMA = \"datalake\"\n",
    "CHUNK_SIZE = 5_000\n",
    "\n",
    "def _ensure_table_and_columns(df: pd.DataFrame, table: str, conn) -> None:\n",
    "    \"\"\"–°–æ–∑–¥–∞—ë—Ç —Ç–∞–±–ª–∏—Ü—É –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã.\"\"\"\n",
    "    insp = inspect(conn)\n",
    "    if not insp.has_table(table, schema=SCHEMA):\n",
    "        df.head(0).to_sql(table, conn, schema=SCHEMA, if_exists=\"replace\", index=False)\n",
    "        return\n",
    "\n",
    "    existing_cols = {c[\"name\"] for c in insp.get_columns(table, schema=SCHEMA)}\n",
    "    missing_cols = [c for c in df.columns if c not in existing_cols]\n",
    "    for col in missing_cols:\n",
    "        sql_type = str(df[col].dtype)\n",
    "        # —É–ø—Ä–æ—â—ë–Ω–Ω–æ: pandas –ø—Ä–∏–≤–µ–¥—ë—Ç –∫ text/varchar; –¥–ª—è —Å—Ç—Ä–æ–≥–æ–π —Ç–∏–ø–∏–∑–∞—Ü–∏–∏ –º–æ–∂–Ω–æ\n",
    "        # –≤—ã–∑–≤–∞—Ç—å pandas.io.sql.get_sqltype –∫–∞–∫ –≤ –ø—Ä–æ—à–ª–æ–π –≤–µ—Ä—Å–∏–∏.\n",
    "        conn.execute(\n",
    "            text(\n",
    "                f'ALTER TABLE \"{SCHEMA}\".\"{table}\" '\n",
    "                f'ADD COLUMN IF NOT EXISTS \"{col}\" {sql_type}'\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def _incremental_append(\n",
    "    df: pd.DataFrame,\n",
    "    table: str,\n",
    "    date_col: str,\n",
    "    conn,\n",
    ") -> int:\n",
    "    \"\"\"–í—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, —É –∫–æ—Ç–æ—Ä—ã—Ö `date_col` > max(date_col) –≤ —Ç–∞–±–ª–∏—Ü–µ.\"\"\"\n",
    "    _ensure_table_and_columns(df, table, conn)\n",
    "\n",
    "    # –µ—Å–ª–∏ –¥–∞—Ç–∞‚Äë–∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç ‚Äî –æ—à–∏–±–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    if date_col not in df.columns:\n",
    "        raise KeyError(f\"–í DataFrame –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π '{date_col}'\")\n",
    "\n",
    "    # –ø–æ–ª—É—á–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É –≤ —Ü–µ–ª–µ–≤–æ–π —Ç–∞–±–ª–∏—Ü–µ\n",
    "    max_date = conn.scalar(\n",
    "        text(\n",
    "            f'SELECT max(\"{date_col}\") FROM \"{SCHEMA}\".\"{table}\"'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_new = df[df[date_col] > max_date] if max_date else df\n",
    "    if df_new.empty:\n",
    "        return 0\n",
    "\n",
    "    df_new.to_sql(\n",
    "        table,\n",
    "        conn,\n",
    "        schema=SCHEMA,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    return len(df_new)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Example usage\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if __name__ == \"__main__\":\n",
    "    tasks: Dict[str, Dict] = {\n",
    "        \"ext_project_sync_designers\": {\n",
    "            \"df\": df_sync_designers,\n",
    "            \"date_col\": \"date\",\n",
    "        },\n",
    "        \"ext_project_sync_bim\": {\n",
    "            \"df\": df_sync_bim,\n",
    "            \"date_col\": \"date\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with engine_postgres.begin() as conn:\n",
    "        db = conn.scalar(text(\"SELECT current_database()\"))\n",
    "        print(\"üîé –ü–æ–¥–∫–ª—é—á–µ–Ω –∫ –±–∞–∑–µ:\", db)\n",
    "\n",
    "        for table, params in tasks.items():\n",
    "            added = _incremental_append(params[\"df\"], table, params[\"date_col\"], conn)\n",
    "            print(f\"‚úÖ {table}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {added} –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫\")\n",
    "            \n",
    "            \n",
    "# from sqlalchemy import text\n",
    "# import pandas as pd\n",
    "\n",
    "# # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ\n",
    "# with engine_postgres.begin() as conn:\n",
    "#     db_name = pd.read_sql(\"SELECT current_database()\", conn)\n",
    "#     print(\"üîé –ü–æ–¥–∫–ª—é—á–µ–Ω –∫ –±–∞–∑–µ:\", db_name.iloc[0, 0])\n",
    "\n",
    "# # ‚úÖ –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã\n",
    "# df_sync_designers.head(0).to_sql(\n",
    "#     \"ext_project_sync_designers\",\n",
    "#     engine_postgres,\n",
    "#     schema=\"datalake\",\n",
    "#     if_exists=\"replace\",  # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç —Ç–∞–±–ª–∏—Ü—É —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏–∑ DataFrame\n",
    "#     index=False\n",
    "# )\n",
    "# print(\"üõ† –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã datalake.test_lake –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –∏–∑ DataFrame.\")\n",
    "\n",
    "# # ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "# df_sync_designers.to_sql(\n",
    "#     \"ext_project_sync_designers\",\n",
    "#     engine_postgres,\n",
    "#     schema=\"datalake\",\n",
    "#     if_exists=\"append\",\n",
    "#     index=False\n",
    "# )\n",
    "# print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(df_sync_designers)}\")\n",
    "\n",
    "# # ‚úÖ –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã\n",
    "# df_sync_bim.head(0).to_sql(\n",
    "#     \"ext_project_sync_bim\",\n",
    "#     engine_postgres,\n",
    "#     schema=\"datalake\",\n",
    "#     if_exists=\"replace\",  # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç —Ç–∞–±–ª–∏—Ü—É —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏–∑ DataFrame\n",
    "#     index=False\n",
    "# )\n",
    "# print(\"üõ† –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã datalake.test_lake –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –∏–∑ DataFrame.\")\n",
    "\n",
    "# # ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "# df_sync_bim.to_sql(\n",
    "#     \"ext_project_sync_bim\",\n",
    "#     engine_postgres,\n",
    "#     schema=\"datalake\",\n",
    "#     if_exists=\"append\",\n",
    "#     index=False\n",
    "# )\n",
    "# print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(df_sync_bim)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}